lista de cambios


Contact Scraper

hacer scroll de 1 a 3 veces random - (tiempo random definido en el .env)
limpiar la redundancia de el cambio de nombres de la tabla en main.py
cambiar la ubicacion de la base de datos
el nombre de la base de datos que sea una variable en el .env
definir un limite de contactos scrapear por corrida variable en .env
definir un limite al dia definido en .env




Main

convertir este main en main_contacts.py y va a ser llamado desde un main.py afuera de src



Url scraper

mover login fuera de utils_scraper a utils y asegurar que solo lo usamos una vez
pedir input del url a scrapear y input del segmento
scrapear urls de la pagina seleccionada y guardar el timestamp
guardar las urls en una nueva tabla de la base de datos
crear navegador que pasa las paginas hasta llegar al final
scrapear cada una de las paginas
poner un limite diario a las paginas que puedes scrapear
conectar load_file con la nueva tabla en la base de datos


CSV export

crear un software que permita exportar la base de datos en csv
crear un sistema de segmentacion para que los csv vengan en los batches para haces las campanas
